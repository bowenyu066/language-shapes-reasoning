{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 0.13381506757660913,
  "eval_steps": 500,
  "global_step": 500,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.0026763013515321826,
      "grad_norm": 26.25660514831543,
      "learning_rate": 9.992007750544876e-06,
      "loss": 12.1612,
      "step": 10
    },
    {
      "epoch": 0.005352602703064365,
      "grad_norm": 37.43777084350586,
      "learning_rate": 9.964413022849069e-06,
      "loss": 6.1383,
      "step": 20
    },
    {
      "epoch": 0.008028904054596548,
      "grad_norm": 266.2800598144531,
      "learning_rate": 9.91722602497665e-06,
      "loss": 1.3793,
      "step": 30
    },
    {
      "epoch": 0.01070520540612873,
      "grad_norm": 384.045166015625,
      "learning_rate": 9.85063298245053e-06,
      "loss": 0.345,
      "step": 40
    },
    {
      "epoch": 0.013381506757660913,
      "grad_norm": 0.5013037919998169,
      "learning_rate": 9.764896707586095e-06,
      "loss": 0.0968,
      "step": 50
    },
    {
      "epoch": 0.016057808109193095,
      "grad_norm": 0.0998208299279213,
      "learning_rate": 9.660355562291055e-06,
      "loss": 0.0784,
      "step": 60
    },
    {
      "epoch": 0.018734109460725276,
      "grad_norm": 0.2038639783859253,
      "learning_rate": 9.537422122705585e-06,
      "loss": 0.0646,
      "step": 70
    },
    {
      "epoch": 0.02141041081225746,
      "grad_norm": 0.11723481863737106,
      "learning_rate": 9.396581550952781e-06,
      "loss": 0.0617,
      "step": 80
    },
    {
      "epoch": 0.02408671216378964,
      "grad_norm": 0.12917624413967133,
      "learning_rate": 9.238389680425417e-06,
      "loss": 0.1036,
      "step": 90
    },
    {
      "epoch": 0.026763013515321826,
      "grad_norm": 0.5151695609092712,
      "learning_rate": 9.06347082216547e-06,
      "loss": 0.0582,
      "step": 100
    },
    {
      "epoch": 0.029439314866854006,
      "grad_norm": 0.16121524572372437,
      "learning_rate": 8.872515300993669e-06,
      "loss": 0.0505,
      "step": 110
    },
    {
      "epoch": 0.03211561621838619,
      "grad_norm": 0.07020791620016098,
      "learning_rate": 8.666276731112802e-06,
      "loss": 0.0517,
      "step": 120
    },
    {
      "epoch": 0.034791917569918375,
      "grad_norm": 0.19844865798950195,
      "learning_rate": 8.445569041936743e-06,
      "loss": 0.0471,
      "step": 130
    },
    {
      "epoch": 0.03746821892145055,
      "grad_norm": 0.0933845043182373,
      "learning_rate": 8.211263265882923e-06,
      "loss": 0.0444,
      "step": 140
    },
    {
      "epoch": 0.04014452027298274,
      "grad_norm": 0.05752415210008621,
      "learning_rate": 7.964284100805297e-06,
      "loss": 0.0416,
      "step": 150
    },
    {
      "epoch": 0.04282082162451492,
      "grad_norm": 0.045192599296569824,
      "learning_rate": 7.70560626063438e-06,
      "loss": 0.0503,
      "step": 160
    },
    {
      "epoch": 0.045497122976047105,
      "grad_norm": 0.03594256937503815,
      "learning_rate": 7.436250628626662e-06,
      "loss": 0.0452,
      "step": 170
    },
    {
      "epoch": 0.04817342432757928,
      "grad_norm": 0.054595742374658585,
      "learning_rate": 7.157280228404796e-06,
      "loss": 0.0491,
      "step": 180
    },
    {
      "epoch": 0.05084972567911147,
      "grad_norm": 0.03524516522884369,
      "learning_rate": 6.869796028689002e-06,
      "loss": 0.0391,
      "step": 190
    },
    {
      "epoch": 0.05352602703064365,
      "grad_norm": 0.08481147885322571,
      "learning_rate": 6.574932598276524e-06,
      "loss": 0.0434,
      "step": 200
    },
    {
      "epoch": 0.056202328382175835,
      "grad_norm": 0.06486243009567261,
      "learning_rate": 6.273853628416911e-06,
      "loss": 0.0431,
      "step": 210
    },
    {
      "epoch": 0.05887862973370801,
      "grad_norm": 0.051614247262477875,
      "learning_rate": 5.967747340254303e-06,
      "loss": 0.0448,
      "step": 220
    },
    {
      "epoch": 0.0615549310852402,
      "grad_norm": 0.0539228729903698,
      "learning_rate": 5.657821795461413e-06,
      "loss": 0.0417,
      "step": 230
    },
    {
      "epoch": 0.06423123243677238,
      "grad_norm": 0.056759219616651535,
      "learning_rate": 5.345300128572031e-06,
      "loss": 0.0451,
      "step": 240
    },
    {
      "epoch": 0.06690753378830457,
      "grad_norm": 0.23539426922798157,
      "learning_rate": 5.031415719827796e-06,
      "loss": 0.045,
      "step": 250
    },
    {
      "epoch": 0.06958383513983675,
      "grad_norm": 0.16362693905830383,
      "learning_rate": 4.717407327589878e-06,
      "loss": 0.0506,
      "step": 260
    },
    {
      "epoch": 0.07226013649136893,
      "grad_norm": 0.41134050488471985,
      "learning_rate": 4.404514199525651e-06,
      "loss": 0.0434,
      "step": 270
    },
    {
      "epoch": 0.0749364378429011,
      "grad_norm": 0.09877727925777435,
      "learning_rate": 4.093971181864313e-06,
      "loss": 0.0344,
      "step": 280
    },
    {
      "epoch": 0.07761273919443329,
      "grad_norm": 0.1980641484260559,
      "learning_rate": 3.787003846022964e-06,
      "loss": 0.0415,
      "step": 290
    },
    {
      "epoch": 0.08028904054596547,
      "grad_norm": 0.1440516710281372,
      "learning_rate": 3.484823651836131e-06,
      "loss": 0.0367,
      "step": 300
    },
    {
      "epoch": 0.08296534189749766,
      "grad_norm": 0.1329314410686493,
      "learning_rate": 3.188623166477272e-06,
      "loss": 0.0433,
      "step": 310
    },
    {
      "epoch": 0.08564164324902984,
      "grad_norm": 0.1592530459165573,
      "learning_rate": 2.899571357940969e-06,
      "loss": 0.0413,
      "step": 320
    },
    {
      "epoch": 0.08831794460056203,
      "grad_norm": 0.08194030821323395,
      "learning_rate": 2.618808981660304e-06,
      "loss": 0.0431,
      "step": 330
    },
    {
      "epoch": 0.09099424595209421,
      "grad_norm": 0.09938821196556091,
      "learning_rate": 2.3474440784663287e-06,
      "loss": 0.0404,
      "step": 340
    },
    {
      "epoch": 0.0936705473036264,
      "grad_norm": 0.060995519161224365,
      "learning_rate": 2.0865476016571206e-06,
      "loss": 0.0434,
      "step": 350
    },
    {
      "epoch": 0.09634684865515857,
      "grad_norm": 0.07593611627817154,
      "learning_rate": 1.837149190434378e-06,
      "loss": 0.0434,
      "step": 360
    },
    {
      "epoch": 0.09902315000669075,
      "grad_norm": 0.12320572882890701,
      "learning_rate": 1.600233106387904e-06,
      "loss": 0.0422,
      "step": 370
    },
    {
      "epoch": 0.10169945135822293,
      "grad_norm": 0.17982622981071472,
      "learning_rate": 1.3767343490647668e-06,
      "loss": 0.044,
      "step": 380
    },
    {
      "epoch": 0.10437575270975512,
      "grad_norm": 0.08887447416782379,
      "learning_rate": 1.1675349659532514e-06,
      "loss": 0.0455,
      "step": 390
    },
    {
      "epoch": 0.1070520540612873,
      "grad_norm": 0.05765724182128906,
      "learning_rate": 9.734605714443906e-07,
      "loss": 0.0358,
      "step": 400
    },
    {
      "epoch": 0.10972835541281949,
      "grad_norm": 0.08564750850200653,
      "learning_rate": 7.952770885091548e-07,
      "loss": 0.0407,
      "step": 410
    },
    {
      "epoch": 0.11240465676435167,
      "grad_norm": 0.0646480917930603,
      "learning_rate": 6.336877259504004e-07,
      "loss": 0.034,
      "step": 420
    },
    {
      "epoch": 0.11508095811588386,
      "grad_norm": 0.048526592552661896,
      "learning_rate": 4.893302031589864e-07,
      "loss": 0.042,
      "step": 430
    },
    {
      "epoch": 0.11775725946741603,
      "grad_norm": 0.06970959901809692,
      "learning_rate": 3.627742333266937e-07,
      "loss": 0.0443,
      "step": 440
    },
    {
      "epoch": 0.12043356081894821,
      "grad_norm": 0.06295232474803925,
      "learning_rate": 2.5451927504852757e-07,
      "loss": 0.0373,
      "step": 450
    },
    {
      "epoch": 0.1231098621704804,
      "grad_norm": 0.04586518183350563,
      "learning_rate": 1.6499256118782503e-07,
      "loss": 0.0449,
      "step": 460
    },
    {
      "epoch": 0.12578616352201258,
      "grad_norm": 0.0860026627779007,
      "learning_rate": 9.454741278333013e-08,
      "loss": 0.0393,
      "step": 470
    },
    {
      "epoch": 0.12846246487354476,
      "grad_norm": 0.053073346614837646,
      "learning_rate": 4.346184465246761e-08,
      "loss": 0.047,
      "step": 480
    },
    {
      "epoch": 0.13113876622507695,
      "grad_norm": 0.16842146217823029,
      "learning_rate": 1.1937468193873869e-08,
      "loss": 0.0407,
      "step": 490
    },
    {
      "epoch": 0.13381506757660913,
      "grad_norm": 0.08425372838973999,
      "learning_rate": 9.869571931442334e-11,
      "loss": 0.0376,
      "step": 500
    }
  ],
  "logging_steps": 10,
  "max_steps": 500,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 1,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 2.11664778559488e+17,
  "train_batch_size": 1,
  "trial_name": null,
  "trial_params": null
}
