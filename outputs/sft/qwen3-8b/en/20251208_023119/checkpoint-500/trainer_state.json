{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 0.13381506757660913,
  "eval_steps": 500,
  "global_step": 500,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.0026763013515321826,
      "grad_norm": 24.674514770507812,
      "learning_rate": 9.992007750544876e-06,
      "loss": 12.3873,
      "step": 10
    },
    {
      "epoch": 0.005352602703064365,
      "grad_norm": 29.833765029907227,
      "learning_rate": 9.964413022849069e-06,
      "loss": 6.2389,
      "step": 20
    },
    {
      "epoch": 0.008028904054596548,
      "grad_norm": 169.08753967285156,
      "learning_rate": 9.91722602497665e-06,
      "loss": 1.9284,
      "step": 30
    },
    {
      "epoch": 0.01070520540612873,
      "grad_norm": 413.3662414550781,
      "learning_rate": 9.85063298245053e-06,
      "loss": 0.6519,
      "step": 40
    },
    {
      "epoch": 0.013381506757660913,
      "grad_norm": 0.4129810631275177,
      "learning_rate": 9.764896707586095e-06,
      "loss": 1.0008,
      "step": 50
    },
    {
      "epoch": 0.016057808109193095,
      "grad_norm": 1.9405326843261719,
      "learning_rate": 9.660355562291055e-06,
      "loss": 0.0752,
      "step": 60
    },
    {
      "epoch": 0.018734109460725276,
      "grad_norm": 0.7720960378646851,
      "learning_rate": 9.537422122705585e-06,
      "loss": 0.065,
      "step": 70
    },
    {
      "epoch": 0.02141041081225746,
      "grad_norm": 2.8328278064727783,
      "learning_rate": 9.396581550952781e-06,
      "loss": 0.0592,
      "step": 80
    },
    {
      "epoch": 0.02408671216378964,
      "grad_norm": 0.35178062319755554,
      "learning_rate": 9.238389680425417e-06,
      "loss": 0.0489,
      "step": 90
    },
    {
      "epoch": 0.026763013515321826,
      "grad_norm": 0.2645021080970764,
      "learning_rate": 9.06347082216547e-06,
      "loss": 0.0475,
      "step": 100
    },
    {
      "epoch": 0.029439314866854006,
      "grad_norm": 0.10777146369218826,
      "learning_rate": 8.872515300993669e-06,
      "loss": 0.04,
      "step": 110
    },
    {
      "epoch": 0.03211561621838619,
      "grad_norm": 0.4074881076812744,
      "learning_rate": 8.666276731112802e-06,
      "loss": 0.0433,
      "step": 120
    },
    {
      "epoch": 0.034791917569918375,
      "grad_norm": 0.5284121632575989,
      "learning_rate": 8.445569041936743e-06,
      "loss": 0.0395,
      "step": 130
    },
    {
      "epoch": 0.03746821892145055,
      "grad_norm": 0.19814935326576233,
      "learning_rate": 8.211263265882923e-06,
      "loss": 0.0368,
      "step": 140
    },
    {
      "epoch": 0.04014452027298274,
      "grad_norm": 0.052307792007923126,
      "learning_rate": 7.964284100805297e-06,
      "loss": 0.0328,
      "step": 150
    },
    {
      "epoch": 0.04282082162451492,
      "grad_norm": 0.07087916880846024,
      "learning_rate": 7.70560626063438e-06,
      "loss": 0.0398,
      "step": 160
    },
    {
      "epoch": 0.045497122976047105,
      "grad_norm": 0.32926949858665466,
      "learning_rate": 7.436250628626662e-06,
      "loss": 0.0358,
      "step": 170
    },
    {
      "epoch": 0.04817342432757928,
      "grad_norm": 0.09922157227993011,
      "learning_rate": 7.157280228404796e-06,
      "loss": 0.0381,
      "step": 180
    },
    {
      "epoch": 0.05084972567911147,
      "grad_norm": 0.09298982471227646,
      "learning_rate": 6.869796028689002e-06,
      "loss": 0.0309,
      "step": 190
    },
    {
      "epoch": 0.05352602703064365,
      "grad_norm": 0.09347342699766159,
      "learning_rate": 6.574932598276524e-06,
      "loss": 0.0309,
      "step": 200
    },
    {
      "epoch": 0.056202328382175835,
      "grad_norm": 0.09612508118152618,
      "learning_rate": 6.273853628416911e-06,
      "loss": 0.0317,
      "step": 210
    },
    {
      "epoch": 0.05887862973370801,
      "grad_norm": 0.08204543590545654,
      "learning_rate": 5.967747340254303e-06,
      "loss": 0.0333,
      "step": 220
    },
    {
      "epoch": 0.0615549310852402,
      "grad_norm": 0.09202475845813751,
      "learning_rate": 5.657821795461413e-06,
      "loss": 0.0299,
      "step": 230
    },
    {
      "epoch": 0.06423123243677238,
      "grad_norm": 0.1147463247179985,
      "learning_rate": 5.345300128572031e-06,
      "loss": 0.0327,
      "step": 240
    },
    {
      "epoch": 0.06690753378830457,
      "grad_norm": 0.09101912379264832,
      "learning_rate": 5.031415719827796e-06,
      "loss": 0.0323,
      "step": 250
    },
    {
      "epoch": 0.06958383513983675,
      "grad_norm": 0.08416697382926941,
      "learning_rate": 4.717407327589878e-06,
      "loss": 0.0371,
      "step": 260
    },
    {
      "epoch": 0.07226013649136893,
      "grad_norm": 0.09221408516168594,
      "learning_rate": 4.404514199525651e-06,
      "loss": 0.0294,
      "step": 270
    },
    {
      "epoch": 0.0749364378429011,
      "grad_norm": 0.06300481408834457,
      "learning_rate": 4.093971181864313e-06,
      "loss": 0.024,
      "step": 280
    },
    {
      "epoch": 0.07761273919443329,
      "grad_norm": 0.09853611141443253,
      "learning_rate": 3.787003846022964e-06,
      "loss": 0.0292,
      "step": 290
    },
    {
      "epoch": 0.08028904054596547,
      "grad_norm": 0.08360105007886887,
      "learning_rate": 3.484823651836131e-06,
      "loss": 0.0253,
      "step": 300
    },
    {
      "epoch": 0.08296534189749766,
      "grad_norm": 0.0624246783554554,
      "learning_rate": 3.188623166477272e-06,
      "loss": 0.0297,
      "step": 310
    },
    {
      "epoch": 0.08564164324902984,
      "grad_norm": 0.07456345856189728,
      "learning_rate": 2.899571357940969e-06,
      "loss": 0.0259,
      "step": 320
    },
    {
      "epoch": 0.08831794460056203,
      "grad_norm": 0.11946635693311691,
      "learning_rate": 2.618808981660304e-06,
      "loss": 0.0275,
      "step": 330
    },
    {
      "epoch": 0.09099424595209421,
      "grad_norm": 0.1558752954006195,
      "learning_rate": 2.3474440784663287e-06,
      "loss": 0.0272,
      "step": 340
    },
    {
      "epoch": 0.0936705473036264,
      "grad_norm": 0.09227344393730164,
      "learning_rate": 2.0865476016571206e-06,
      "loss": 0.0273,
      "step": 350
    },
    {
      "epoch": 0.09634684865515857,
      "grad_norm": 0.0975770652294159,
      "learning_rate": 1.837149190434378e-06,
      "loss": 0.0303,
      "step": 360
    },
    {
      "epoch": 0.09902315000669075,
      "grad_norm": 0.4227941930294037,
      "learning_rate": 1.600233106387904e-06,
      "loss": 0.0276,
      "step": 370
    },
    {
      "epoch": 0.10169945135822293,
      "grad_norm": 0.11940206587314606,
      "learning_rate": 1.3767343490647668e-06,
      "loss": 0.0296,
      "step": 380
    },
    {
      "epoch": 0.10437575270975512,
      "grad_norm": 0.06519393622875214,
      "learning_rate": 1.1675349659532514e-06,
      "loss": 0.0305,
      "step": 390
    },
    {
      "epoch": 0.1070520540612873,
      "grad_norm": 0.1255263239145279,
      "learning_rate": 9.734605714443906e-07,
      "loss": 0.024,
      "step": 400
    },
    {
      "epoch": 0.10972835541281949,
      "grad_norm": 0.08235878497362137,
      "learning_rate": 7.952770885091548e-07,
      "loss": 0.0271,
      "step": 410
    },
    {
      "epoch": 0.11240465676435167,
      "grad_norm": 0.0824064090847969,
      "learning_rate": 6.336877259504004e-07,
      "loss": 0.024,
      "step": 420
    },
    {
      "epoch": 0.11508095811588386,
      "grad_norm": 0.10805729031562805,
      "learning_rate": 4.893302031589864e-07,
      "loss": 0.0302,
      "step": 430
    },
    {
      "epoch": 0.11775725946741603,
      "grad_norm": 0.0798284262418747,
      "learning_rate": 3.627742333266937e-07,
      "loss": 0.0312,
      "step": 440
    },
    {
      "epoch": 0.12043356081894821,
      "grad_norm": 0.09405440092086792,
      "learning_rate": 2.5451927504852757e-07,
      "loss": 0.0243,
      "step": 450
    },
    {
      "epoch": 0.1231098621704804,
      "grad_norm": 0.08936844766139984,
      "learning_rate": 1.6499256118782503e-07,
      "loss": 0.0305,
      "step": 460
    },
    {
      "epoch": 0.12578616352201258,
      "grad_norm": 0.18811920285224915,
      "learning_rate": 9.454741278333013e-08,
      "loss": 0.0274,
      "step": 470
    },
    {
      "epoch": 0.12846246487354476,
      "grad_norm": 0.11836224049329758,
      "learning_rate": 4.346184465246761e-08,
      "loss": 0.0328,
      "step": 480
    },
    {
      "epoch": 0.13113876622507695,
      "grad_norm": 0.11064034700393677,
      "learning_rate": 1.1937468193873869e-08,
      "loss": 0.0258,
      "step": 490
    },
    {
      "epoch": 0.13381506757660913,
      "grad_norm": 0.10083157569169998,
      "learning_rate": 9.869571931442334e-11,
      "loss": 0.0259,
      "step": 500
    }
  ],
  "logging_steps": 10,
  "max_steps": 500,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 1,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 2.11664778559488e+17,
  "train_batch_size": 1,
  "trial_name": null,
  "trial_params": null
}
