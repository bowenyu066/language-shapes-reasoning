{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 0.13381506757660913,
  "eval_steps": 500,
  "global_step": 500,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.0026763013515321826,
      "grad_norm": 116.42154693603516,
      "learning_rate": 9.992007750544876e-06,
      "loss": 11.8425,
      "step": 10
    },
    {
      "epoch": 0.005352602703064365,
      "grad_norm": 4.241674900054932,
      "learning_rate": 9.964413022849069e-06,
      "loss": 1.6032,
      "step": 20
    },
    {
      "epoch": 0.008028904054596548,
      "grad_norm": 0.10872965306043625,
      "learning_rate": 9.91722602497665e-06,
      "loss": 0.0674,
      "step": 30
    },
    {
      "epoch": 0.01070520540612873,
      "grad_norm": 0.10730770975351334,
      "learning_rate": 9.85063298245053e-06,
      "loss": 0.0671,
      "step": 40
    },
    {
      "epoch": 0.013381506757660913,
      "grad_norm": 0.12143336981534958,
      "learning_rate": 9.764896707586095e-06,
      "loss": 0.0588,
      "step": 50
    },
    {
      "epoch": 0.016057808109193095,
      "grad_norm": 0.1322137862443924,
      "learning_rate": 9.660355562291055e-06,
      "loss": 0.0572,
      "step": 60
    },
    {
      "epoch": 0.018734109460725276,
      "grad_norm": 0.09813171625137329,
      "learning_rate": 9.537422122705585e-06,
      "loss": 0.05,
      "step": 70
    },
    {
      "epoch": 0.02141041081225746,
      "grad_norm": 0.10776728391647339,
      "learning_rate": 9.396581550952781e-06,
      "loss": 0.0485,
      "step": 80
    },
    {
      "epoch": 0.02408671216378964,
      "grad_norm": 0.0776965469121933,
      "learning_rate": 9.238389680425417e-06,
      "loss": 0.0461,
      "step": 90
    },
    {
      "epoch": 0.026763013515321826,
      "grad_norm": 0.10096395760774612,
      "learning_rate": 9.06347082216547e-06,
      "loss": 0.0503,
      "step": 100
    },
    {
      "epoch": 0.029439314866854006,
      "grad_norm": 0.10157586634159088,
      "learning_rate": 8.872515300993669e-06,
      "loss": 0.0441,
      "step": 110
    },
    {
      "epoch": 0.03211561621838619,
      "grad_norm": 0.08654556423425674,
      "learning_rate": 8.666276731112802e-06,
      "loss": 0.0471,
      "step": 120
    },
    {
      "epoch": 0.034791917569918375,
      "grad_norm": 0.07921306788921356,
      "learning_rate": 8.445569041936743e-06,
      "loss": 0.0435,
      "step": 130
    },
    {
      "epoch": 0.03746821892145055,
      "grad_norm": 0.08428561687469482,
      "learning_rate": 8.211263265882923e-06,
      "loss": 0.0408,
      "step": 140
    },
    {
      "epoch": 0.04014452027298274,
      "grad_norm": 0.0883556678891182,
      "learning_rate": 7.964284100805297e-06,
      "loss": 0.039,
      "step": 150
    },
    {
      "epoch": 0.04282082162451492,
      "grad_norm": 0.10194613039493561,
      "learning_rate": 7.70560626063438e-06,
      "loss": 0.0496,
      "step": 160
    },
    {
      "epoch": 0.045497122976047105,
      "grad_norm": 0.07619732618331909,
      "learning_rate": 7.436250628626662e-06,
      "loss": 0.0441,
      "step": 170
    },
    {
      "epoch": 0.04817342432757928,
      "grad_norm": 0.09312579780817032,
      "learning_rate": 7.157280228404796e-06,
      "loss": 0.0484,
      "step": 180
    },
    {
      "epoch": 0.05084972567911147,
      "grad_norm": 0.065228171646595,
      "learning_rate": 6.869796028689002e-06,
      "loss": 0.0382,
      "step": 190
    },
    {
      "epoch": 0.05352602703064365,
      "grad_norm": 0.11444857716560364,
      "learning_rate": 6.574932598276524e-06,
      "loss": 0.0419,
      "step": 200
    },
    {
      "epoch": 0.056202328382175835,
      "grad_norm": 0.07135210186243057,
      "learning_rate": 6.273853628416911e-06,
      "loss": 0.0426,
      "step": 210
    },
    {
      "epoch": 0.05887862973370801,
      "grad_norm": 0.07128378748893738,
      "learning_rate": 5.967747340254303e-06,
      "loss": 0.0431,
      "step": 220
    },
    {
      "epoch": 0.0615549310852402,
      "grad_norm": 0.09221962839365005,
      "learning_rate": 5.657821795461413e-06,
      "loss": 0.0404,
      "step": 230
    },
    {
      "epoch": 0.06423123243677238,
      "grad_norm": 0.09360282868146896,
      "learning_rate": 5.345300128572031e-06,
      "loss": 0.0456,
      "step": 240
    },
    {
      "epoch": 0.06690753378830457,
      "grad_norm": 0.10753216594457626,
      "learning_rate": 5.031415719827796e-06,
      "loss": 0.0452,
      "step": 250
    },
    {
      "epoch": 0.06958383513983675,
      "grad_norm": 0.10301036387681961,
      "learning_rate": 4.717407327589878e-06,
      "loss": 0.0503,
      "step": 260
    },
    {
      "epoch": 0.07226013649136893,
      "grad_norm": 0.08112849295139313,
      "learning_rate": 4.404514199525651e-06,
      "loss": 0.0424,
      "step": 270
    },
    {
      "epoch": 0.0749364378429011,
      "grad_norm": 0.06714768707752228,
      "learning_rate": 4.093971181864313e-06,
      "loss": 0.0333,
      "step": 280
    },
    {
      "epoch": 0.07761273919443329,
      "grad_norm": 0.09351318329572678,
      "learning_rate": 3.787003846022964e-06,
      "loss": 0.041,
      "step": 290
    },
    {
      "epoch": 0.08028904054596547,
      "grad_norm": 0.07939894497394562,
      "learning_rate": 3.484823651836131e-06,
      "loss": 0.0359,
      "step": 300
    },
    {
      "epoch": 0.08296534189749766,
      "grad_norm": 0.06976887583732605,
      "learning_rate": 3.188623166477272e-06,
      "loss": 0.0451,
      "step": 310
    },
    {
      "epoch": 0.08564164324902984,
      "grad_norm": 0.12162885069847107,
      "learning_rate": 2.899571357940969e-06,
      "loss": 0.0411,
      "step": 320
    },
    {
      "epoch": 0.08831794460056203,
      "grad_norm": 0.09620866924524307,
      "learning_rate": 2.618808981660304e-06,
      "loss": 0.0432,
      "step": 330
    },
    {
      "epoch": 0.09099424595209421,
      "grad_norm": 0.08146066963672638,
      "learning_rate": 2.3474440784663287e-06,
      "loss": 0.0413,
      "step": 340
    },
    {
      "epoch": 0.0936705473036264,
      "grad_norm": 0.07368423044681549,
      "learning_rate": 2.0865476016571206e-06,
      "loss": 0.0447,
      "step": 350
    },
    {
      "epoch": 0.09634684865515857,
      "grad_norm": 0.07680556178092957,
      "learning_rate": 1.837149190434378e-06,
      "loss": 0.045,
      "step": 360
    },
    {
      "epoch": 0.09902315000669075,
      "grad_norm": 0.08469792455434799,
      "learning_rate": 1.600233106387904e-06,
      "loss": 0.0426,
      "step": 370
    },
    {
      "epoch": 0.10169945135822293,
      "grad_norm": 0.13906611502170563,
      "learning_rate": 1.3767343490647668e-06,
      "loss": 0.0453,
      "step": 380
    },
    {
      "epoch": 0.10437575270975512,
      "grad_norm": 0.06739277392625809,
      "learning_rate": 1.1675349659532514e-06,
      "loss": 0.0475,
      "step": 390
    },
    {
      "epoch": 0.1070520540612873,
      "grad_norm": 0.10019421577453613,
      "learning_rate": 9.734605714443906e-07,
      "loss": 0.0366,
      "step": 400
    },
    {
      "epoch": 0.10972835541281949,
      "grad_norm": 0.08225391060113907,
      "learning_rate": 7.952770885091548e-07,
      "loss": 0.0425,
      "step": 410
    },
    {
      "epoch": 0.11240465676435167,
      "grad_norm": 0.08086161315441132,
      "learning_rate": 6.336877259504004e-07,
      "loss": 0.036,
      "step": 420
    },
    {
      "epoch": 0.11508095811588386,
      "grad_norm": 0.07477821409702301,
      "learning_rate": 4.893302031589864e-07,
      "loss": 0.0434,
      "step": 430
    },
    {
      "epoch": 0.11775725946741603,
      "grad_norm": 0.07784012705087662,
      "learning_rate": 3.627742333266937e-07,
      "loss": 0.0459,
      "step": 440
    },
    {
      "epoch": 0.12043356081894821,
      "grad_norm": 0.10487020760774612,
      "learning_rate": 2.5451927504852757e-07,
      "loss": 0.0386,
      "step": 450
    },
    {
      "epoch": 0.1231098621704804,
      "grad_norm": 0.08236756175756454,
      "learning_rate": 1.6499256118782503e-07,
      "loss": 0.0462,
      "step": 460
    },
    {
      "epoch": 0.12578616352201258,
      "grad_norm": 0.08419014513492584,
      "learning_rate": 9.454741278333013e-08,
      "loss": 0.041,
      "step": 470
    },
    {
      "epoch": 0.12846246487354476,
      "grad_norm": 0.08919797092676163,
      "learning_rate": 4.346184465246761e-08,
      "loss": 0.0499,
      "step": 480
    },
    {
      "epoch": 0.13113876622507695,
      "grad_norm": 0.08547568321228027,
      "learning_rate": 1.1937468193873869e-08,
      "loss": 0.0421,
      "step": 490
    },
    {
      "epoch": 0.13381506757660913,
      "grad_norm": 0.09282954782247543,
      "learning_rate": 9.869571931442334e-11,
      "loss": 0.0396,
      "step": 500
    }
  ],
  "logging_steps": 10,
  "max_steps": 500,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 1,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 2.09815439671296e+17,
  "train_batch_size": 1,
  "trial_name": null,
  "trial_params": null
}
