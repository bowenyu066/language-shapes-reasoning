{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 0.13381506757660913,
  "eval_steps": 500,
  "global_step": 500,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.0026763013515321826,
      "grad_norm": 120.89629364013672,
      "learning_rate": 9.992007750544876e-06,
      "loss": 11.8961,
      "step": 10
    },
    {
      "epoch": 0.005352602703064365,
      "grad_norm": 3.674668788909912,
      "learning_rate": 9.964413022849069e-06,
      "loss": 1.5303,
      "step": 20
    },
    {
      "epoch": 0.008028904054596548,
      "grad_norm": 0.09421630948781967,
      "learning_rate": 9.91722602497665e-06,
      "loss": 0.062,
      "step": 30
    },
    {
      "epoch": 0.01070520540612873,
      "grad_norm": 0.09590603411197662,
      "learning_rate": 9.85063298245053e-06,
      "loss": 0.057,
      "step": 40
    },
    {
      "epoch": 0.013381506757660913,
      "grad_norm": 0.09849923849105835,
      "learning_rate": 9.764896707586095e-06,
      "loss": 0.049,
      "step": 50
    },
    {
      "epoch": 0.016057808109193095,
      "grad_norm": 0.10603917390108109,
      "learning_rate": 9.660355562291055e-06,
      "loss": 0.048,
      "step": 60
    },
    {
      "epoch": 0.018734109460725276,
      "grad_norm": 0.07858186960220337,
      "learning_rate": 9.537422122705585e-06,
      "loss": 0.0445,
      "step": 70
    },
    {
      "epoch": 0.02141041081225746,
      "grad_norm": 0.10568111389875412,
      "learning_rate": 9.396581550952781e-06,
      "loss": 0.0417,
      "step": 80
    },
    {
      "epoch": 0.02408671216378964,
      "grad_norm": 0.06593075394630432,
      "learning_rate": 9.238389680425417e-06,
      "loss": 0.0385,
      "step": 90
    },
    {
      "epoch": 0.026763013515321826,
      "grad_norm": 0.07236000150442123,
      "learning_rate": 9.06347082216547e-06,
      "loss": 0.041,
      "step": 100
    },
    {
      "epoch": 0.029439314866854006,
      "grad_norm": 0.07154294103384018,
      "learning_rate": 8.872515300993669e-06,
      "loss": 0.0354,
      "step": 110
    },
    {
      "epoch": 0.03211561621838619,
      "grad_norm": 0.07026852667331696,
      "learning_rate": 8.666276731112802e-06,
      "loss": 0.0402,
      "step": 120
    },
    {
      "epoch": 0.034791917569918375,
      "grad_norm": 0.0572410449385643,
      "learning_rate": 8.445569041936743e-06,
      "loss": 0.0382,
      "step": 130
    },
    {
      "epoch": 0.03746821892145055,
      "grad_norm": 0.06561300903558731,
      "learning_rate": 8.211263265882923e-06,
      "loss": 0.0363,
      "step": 140
    },
    {
      "epoch": 0.04014452027298274,
      "grad_norm": 0.0585300475358963,
      "learning_rate": 7.964284100805297e-06,
      "loss": 0.0327,
      "step": 150
    },
    {
      "epoch": 0.04282082162451492,
      "grad_norm": 0.05880065634846687,
      "learning_rate": 7.70560626063438e-06,
      "loss": 0.042,
      "step": 160
    },
    {
      "epoch": 0.045497122976047105,
      "grad_norm": 0.06768028438091278,
      "learning_rate": 7.436250628626662e-06,
      "loss": 0.0381,
      "step": 170
    },
    {
      "epoch": 0.04817342432757928,
      "grad_norm": 0.069251149892807,
      "learning_rate": 7.157280228404796e-06,
      "loss": 0.0421,
      "step": 180
    },
    {
      "epoch": 0.05084972567911147,
      "grad_norm": 0.05576580390334129,
      "learning_rate": 6.869796028689002e-06,
      "loss": 0.0328,
      "step": 190
    },
    {
      "epoch": 0.05352602703064365,
      "grad_norm": 0.08018911629915237,
      "learning_rate": 6.574932598276524e-06,
      "loss": 0.0343,
      "step": 200
    },
    {
      "epoch": 0.056202328382175835,
      "grad_norm": 0.05692315846681595,
      "learning_rate": 6.273853628416911e-06,
      "loss": 0.0353,
      "step": 210
    },
    {
      "epoch": 0.05887862973370801,
      "grad_norm": 0.054984938353300095,
      "learning_rate": 5.967747340254303e-06,
      "loss": 0.0387,
      "step": 220
    },
    {
      "epoch": 0.0615549310852402,
      "grad_norm": 0.07422430068254471,
      "learning_rate": 5.657821795461413e-06,
      "loss": 0.0337,
      "step": 230
    },
    {
      "epoch": 0.06423123243677238,
      "grad_norm": 0.07052432000637054,
      "learning_rate": 5.345300128572031e-06,
      "loss": 0.0375,
      "step": 240
    },
    {
      "epoch": 0.06690753378830457,
      "grad_norm": 0.06469980627298355,
      "learning_rate": 5.031415719827796e-06,
      "loss": 0.0375,
      "step": 250
    },
    {
      "epoch": 0.06958383513983675,
      "grad_norm": 0.14602641761302948,
      "learning_rate": 4.717407327589878e-06,
      "loss": 0.0442,
      "step": 260
    },
    {
      "epoch": 0.07226013649136893,
      "grad_norm": 0.10782565921545029,
      "learning_rate": 4.404514199525651e-06,
      "loss": 0.0348,
      "step": 270
    },
    {
      "epoch": 0.0749364378429011,
      "grad_norm": 0.05078670009970665,
      "learning_rate": 4.093971181864313e-06,
      "loss": 0.028,
      "step": 280
    },
    {
      "epoch": 0.07761273919443329,
      "grad_norm": 0.08035007119178772,
      "learning_rate": 3.787003846022964e-06,
      "loss": 0.0358,
      "step": 290
    },
    {
      "epoch": 0.08028904054596547,
      "grad_norm": 0.05333714932203293,
      "learning_rate": 3.484823651836131e-06,
      "loss": 0.031,
      "step": 300
    },
    {
      "epoch": 0.08296534189749766,
      "grad_norm": 0.045328471809625626,
      "learning_rate": 3.188623166477272e-06,
      "loss": 0.0372,
      "step": 310
    },
    {
      "epoch": 0.08564164324902984,
      "grad_norm": 0.05602288991212845,
      "learning_rate": 2.899571357940969e-06,
      "loss": 0.0327,
      "step": 320
    },
    {
      "epoch": 0.08831794460056203,
      "grad_norm": 0.05546382814645767,
      "learning_rate": 2.618808981660304e-06,
      "loss": 0.0348,
      "step": 330
    },
    {
      "epoch": 0.09099424595209421,
      "grad_norm": 0.08423103392124176,
      "learning_rate": 2.3474440784663287e-06,
      "loss": 0.0341,
      "step": 340
    },
    {
      "epoch": 0.0936705473036264,
      "grad_norm": 0.06010559946298599,
      "learning_rate": 2.0865476016571206e-06,
      "loss": 0.0361,
      "step": 350
    },
    {
      "epoch": 0.09634684865515857,
      "grad_norm": 0.062031928449869156,
      "learning_rate": 1.837149190434378e-06,
      "loss": 0.0383,
      "step": 360
    },
    {
      "epoch": 0.09902315000669075,
      "grad_norm": 0.07552918046712875,
      "learning_rate": 1.600233106387904e-06,
      "loss": 0.0369,
      "step": 370
    },
    {
      "epoch": 0.10169945135822293,
      "grad_norm": 0.10047080367803574,
      "learning_rate": 1.3767343490647668e-06,
      "loss": 0.0366,
      "step": 380
    },
    {
      "epoch": 0.10437575270975512,
      "grad_norm": 0.051360197365283966,
      "learning_rate": 1.1675349659532514e-06,
      "loss": 0.0392,
      "step": 390
    },
    {
      "epoch": 0.1070520540612873,
      "grad_norm": 0.062327753752470016,
      "learning_rate": 9.734605714443906e-07,
      "loss": 0.0319,
      "step": 400
    },
    {
      "epoch": 0.10972835541281949,
      "grad_norm": 0.05329582095146179,
      "learning_rate": 7.952770885091548e-07,
      "loss": 0.0339,
      "step": 410
    },
    {
      "epoch": 0.11240465676435167,
      "grad_norm": 0.04813884198665619,
      "learning_rate": 6.336877259504004e-07,
      "loss": 0.0309,
      "step": 420
    },
    {
      "epoch": 0.11508095811588386,
      "grad_norm": 0.053506504744291306,
      "learning_rate": 4.893302031589864e-07,
      "loss": 0.0392,
      "step": 430
    },
    {
      "epoch": 0.11775725946741603,
      "grad_norm": 0.06659353524446487,
      "learning_rate": 3.627742333266937e-07,
      "loss": 0.0394,
      "step": 440
    },
    {
      "epoch": 0.12043356081894821,
      "grad_norm": 0.07303856313228607,
      "learning_rate": 2.5451927504852757e-07,
      "loss": 0.0305,
      "step": 450
    },
    {
      "epoch": 0.1231098621704804,
      "grad_norm": 0.05834922939538956,
      "learning_rate": 1.6499256118782503e-07,
      "loss": 0.0395,
      "step": 460
    },
    {
      "epoch": 0.12578616352201258,
      "grad_norm": 0.0582008995115757,
      "learning_rate": 9.454741278333013e-08,
      "loss": 0.0362,
      "step": 470
    },
    {
      "epoch": 0.12846246487354476,
      "grad_norm": 0.07349423319101334,
      "learning_rate": 4.346184465246761e-08,
      "loss": 0.0412,
      "step": 480
    },
    {
      "epoch": 0.13113876622507695,
      "grad_norm": 0.06925282627344131,
      "learning_rate": 1.1937468193873869e-08,
      "loss": 0.0355,
      "step": 490
    },
    {
      "epoch": 0.13381506757660913,
      "grad_norm": 0.06574368476867676,
      "learning_rate": 9.869571931442334e-11,
      "loss": 0.0342,
      "step": 500
    }
  ],
  "logging_steps": 10,
  "max_steps": 500,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 1,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 2.09815439671296e+17,
  "train_batch_size": 1,
  "trial_name": null,
  "trial_params": null
}
