{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3323e465",
   "metadata": {},
   "source": [
    "Note: This notebook can only be run on Google Colab or Modal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3da5bc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -U torch==2.8.0 torchvision transformers datasets accelerate trl evaluate bitsandbytes wandb peft\n",
    "!pip install math-verify[antlr4_13_2]\n",
    "!pip install -U flash-attn --no-build-isolation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "214da463",
   "metadata": {},
   "source": [
    "Evaluate open-source models on GSM8K (English + Chinese).\n",
    "\n",
    "Models: Qwen3-8B, Llama-3.1-8B, DeepSeekMath-7B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6222475f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "from re import L\n",
    "import sys\n",
    "from typing import List, Tuple, Optional\n",
    "\n",
    "# Add parent directory to path for imports\n",
    "sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))\n",
    "\n",
    "from src.model_interface import LocalModel\n",
    "from src.eval_runner import run_experiment, generate_output_path\n",
    "from src.data_utils import ensure_dir\n",
    "\n",
    "\n",
    "# Model configurations\n",
    "LOCAL_MODELS = {\n",
    "    \"qwen3-8b\": {\n",
    "        \"model_path\": \"Qwen/Qwen3-8B\",\n",
    "        \"backend\": \"transformers\",\n",
    "        \"use_temperature\": True,\n",
    "        \"temperature\": 0.6,\n",
    "        \"top_p\": 0.95,\n",
    "        \"top_k\": 20\n",
    "    },\n",
    "    \"llama-3.1-8b\": {\n",
    "        \"model_path\": \"meta-llama/Llama-3.1-8B-Instruct\",\n",
    "        \"backend\": \"transformers\",\n",
    "        \"use_temperature\": True,\n",
    "        \"temperature\": 0.6,\n",
    "        \"top_p\": 0.95,\n",
    "        \"top_k\": 20\n",
    "    },\n",
    "    \"deepseekmath-7b\": {\n",
    "        \"model_path\": \"deepseek-ai/deepseek-math-7b-instruct\",\n",
    "        \"backend\": \"transformers\",\n",
    "        \"use_temperature\": True,\n",
    "        \"temperature\": 0.6,\n",
    "        \"top_p\": 0.95,\n",
    "        \"top_k\": 20\n",
    "    }\n",
    "}\n",
    "\n",
    "# Experiment configurations\n",
    "EXPERIMENT_CONFIGS = [\n",
    "    # (language, mode, max_tokens)\n",
    "    (\"en\", \"direct\", 128),\n",
    "    (\"en\", \"direct\", 256),\n",
    "    (\"zh\", \"direct\", 128),\n",
    "    (\"zh\", \"direct\", 256),\n",
    "    (\"zh\", \"zh_translate_then_solve\", 256),\n",
    "]\n",
    "\n",
    "\n",
    "def create_model(model_name: str) -> LocalModel:\n",
    "    \"\"\"Create a LocalModel instance.\"\"\"\n",
    "    if model_name not in LOCAL_MODELS:\n",
    "        raise ValueError(f\"Unknown model: {model_name}. Available: {List(LOCAL_MODELS.keys())}\")\n",
    "    \n",
    "    config = LOCAL_MODELS[model_name]\n",
    "    return LocalModel(\n",
    "        name=model_name,\n",
    "        model_path=config[\"model_path\"],\n",
    "        backend=config[\"backend\"],\n",
    "    )\n",
    "\n",
    "\n",
    "def get_dataset_path(language: str) -> str:\n",
    "    \"\"\"Get the dataset path for a language.\"\"\"\n",
    "    return f\"data/processed/gsm8k/gsm8k_{language}_test.jsonl\"\n",
    "\n",
    "\n",
    "def run_all_experiments(\n",
    "    models: List[str],\n",
    "    configs: List[Tuple],\n",
    "    output_dir: str,\n",
    "    limit: int | None = None\n",
    "):\n",
    "    \"\"\"\n",
    "    Run all experiment configurations.\n",
    "    \n",
    "    Args:\n",
    "        models: List of model names to evaluate.\n",
    "        configs: List of (language, mode, max_tokens) tuples.\n",
    "        output_dir: Directory to save results.\n",
    "        limit: Optional limit on examples per experiment.\n",
    "    \"\"\"\n",
    "    ensure_dir(output_dir)\n",
    "    \n",
    "    summaries = []\n",
    "    \n",
    "    for model_name in models:\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"Model: {model_name}\")\n",
    "        print(f\"{'='*60}\")\n",
    "        \n",
    "        try:\n",
    "            model = create_model(model_name)\n",
    "        except Exception as e:\n",
    "            print(f\"Error creating model {model_name}: {e}\")\n",
    "            continue\n",
    "        \n",
    "        for language, mode, max_tokens in configs:\n",
    "            # Skip translate-then-solve for English\n",
    "            if mode == \"zh_translate_then_solve\" and language == \"en\":\n",
    "                continue\n",
    "            \n",
    "            dataset_path = get_dataset_path(language)\n",
    "            \n",
    "            if not os.path.exists(dataset_path):\n",
    "                print(f\"Warning: Dataset not found: {dataset_path}\")\n",
    "                continue\n",
    "            \n",
    "            output_path = generate_output_path(\n",
    "                output_dir=output_dir,\n",
    "                dataset_name=\"gsm8k\",\n",
    "                model_name=model_name,\n",
    "                language=language,\n",
    "                mode=mode,\n",
    "                max_tokens=max_tokens\n",
    "            )\n",
    "            \n",
    "            try:\n",
    "                summary = run_experiment(\n",
    "                    model=model,\n",
    "                    dataset_path=dataset_path,\n",
    "                    dataset_name=\"gsm8k\",\n",
    "                    language=language,\n",
    "                    mode=mode,\n",
    "                    max_tokens=max_tokens,\n",
    "                    output_csv_path=output_path,\n",
    "                    limit=limit\n",
    "                )\n",
    "                summaries.append(summary)\n",
    "            except NotImplementedError as e:\n",
    "                print(f\"Skipping (not implemented): {e}\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error in experiment: {e}\")\n",
    "    \n",
    "    return summaries\n",
    "\n",
    "\n",
    "def main(\n",
    "    models: str | List[str] = List(LOCAL_MODELS.keys()),\n",
    "    language: str | List[str] = [\"en\", \"zh\"],\n",
    "    mode: str | List[str] = [\"direct\", \"zh_translate_then_solve\"],\n",
    "    max_tokens: Optional[int] = None,\n",
    "    configs: List[Tuple] = EXPERIMENT_CONFIGS,\n",
    "    output_dir: str = \"results/gsm8k\",\n",
    "    limit: int | None = None,\n",
    "):\n",
    "    \"\"\"Main entry point.\"\"\"\n",
    "    # Determine configs to run\n",
    "    configs = []\n",
    "    for exp_lang, exp_mode, exp_max_tok in EXPERIMENT_CONFIGS:\n",
    "        if exp_lang != language:\n",
    "            continue\n",
    "        if exp_mode != mode:\n",
    "            continue\n",
    "        if max_tokens:\n",
    "            exp_max_tok = max_tokens\n",
    "        configs.append((exp_lang, exp_mode, exp_max_tok))\n",
    "    \n",
    "    print(\"=\" * 60)\n",
    "    print(\"GSM8K Local Model Evaluation\")\n",
    "    print(\"=\" * 60)\n",
    "    print(f\"Models: {models}\")\n",
    "    print(f\"Configs: {configs}\")\n",
    "    print(f\"Output: {output_dir}\")\n",
    "    if limit:\n",
    "        print(f\"Limit: {limit} examples per experiment\")\n",
    "    \n",
    "    # Run experiments\n",
    "    summaries = run_all_experiments(\n",
    "        models=models,\n",
    "        configs=configs,\n",
    "        output_dir=output_dir,\n",
    "        limit=limit\n",
    "    )\n",
    "    \n",
    "    # Print summary\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"Summary\")\n",
    "    print(\"=\" * 60)\n",
    "    for s in summaries:\n",
    "        print(f\"{s['model']} | {s['language']} | {s['mode']} | \"\n",
    "              f\"acc={s['accuracy']:.4f} ({s['correct']}/{s['n']})\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"Evaluation complete!\")\n",
    "    print(f\"Results saved to: {output_dir}\")\n",
    "    print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba978d0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "main(\n",
    "    models=\"qwen3-8b\",\n",
    "    language=\"en\",\n",
    "    mode=\"direct\",\n",
    "    limit=10\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lang-shapes-reasoning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
